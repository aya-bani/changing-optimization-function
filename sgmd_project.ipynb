{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aya-bani/changing-optimization-function/blob/main/sgmd_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynW_9kbzgI4L",
        "outputId": "c83ce513-a874-4ef7-a24b-a69941ba92aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MGWud4i9gaP_"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, tensorflow as tf, random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OLdNWCtsgfJP"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed); random.seed(seed); tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cfEZcye6ghow"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/projet mit/data.csv\", encoding=\"latin1\")\n",
        "X = data[[\"Tf_in\",\"Ua\",\"Uw\"]].values\n",
        "y = data[\"Y\"].values.reshape(-1,1)\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "Xs = scaler_X.fit_transform(X)\n",
        "scaler_y = MinMaxScaler(feature_range=(0.2, 0.8))\n",
        "ys = scaler_y.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xBjSpy-lglxn"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(Xs, ys, test_size=0.30, random_state=42)\n",
        "X_val,   X_test, y_val,   y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bs2Qnf-wgrVI"
      },
      "outputs": [],
      "source": [
        "def build_model_final(layers=[10,5], hidden_act=\"sigmoid\", out_act=\"sigmoid\", lr=0.01):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(3,)))\n",
        "\n",
        "    # Hidden layers\n",
        "    model.add(Dense(layers[0], activation=hidden_act))\n",
        "    for n in layers[1:]:\n",
        "        model.add(Dense(n, activation=hidden_act))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation=out_act))\n",
        "\n",
        "    # Fixed optimizer (Adam, lr=0.01)\n",
        "    opt = Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qFzfGAn9gvTP"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X, y, scaler_y):\n",
        "    # Predict\n",
        "    y_pred = model.predict(X, verbose=0)\n",
        "\n",
        "    # Inverse transform back to original scale\n",
        "    y_true = scaler_y.inverse_transform(y)\n",
        "    y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
        "\n",
        "    # Return metrics\n",
        "    return (\n",
        "        mean_squared_error(y_true, y_pred_inv),   # MSE\n",
        "        mean_absolute_error(y_true, y_pred_inv),  # MAE\n",
        "        r2_score(y_true, y_pred_inv)              # R²\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5LKFY5FEgygn"
      },
      "outputs": [],
      "source": [
        "def sweep_optims(layers=[10,5], acts=\"sigmoid\"):\n",
        "    results = []\n",
        "    for opt in [\"adam\"]:   # keep only the best optimizer\n",
        "        # finer learning rates around 0.01\n",
        "        for lr in [0.005, 0.007, 0.01, 0.02]:\n",
        "            set_seeds(42); K.clear_session()\n",
        "            model = build_model_opt(layers, hidden_act=acts, out_act=\"sigmoid\", optimizer=opt, lr=lr)\n",
        "\n",
        "            es = EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=True)\n",
        "            hist = model.fit(\n",
        "                X_train, y_train,\n",
        "                validation_data=(X_val, y_val),\n",
        "                epochs=1000, batch_size=8, verbose=0,\n",
        "                callbacks=[es]\n",
        "            )\n",
        "\n",
        "            # Pass scaler_y explicitly\n",
        "            tr = evaluate_model(model, X_train, y_train, scaler_y)\n",
        "            va = evaluate_model(model, X_val, y_val, scaler_y)\n",
        "            te = evaluate_model(model, X_test, y_test, scaler_y)\n",
        "\n",
        "            results.append({\n",
        "                \"optimizer\": opt,\n",
        "                \"lr\": lr,\n",
        "                \"train_r2\": tr[2], \"val_r2\": va[2], \"test_r2\": te[2],\n",
        "                \"val_mse\": va[0], \"test_mse\": te[0],\n",
        "                \"val_mae\": va[1], \"test_mae\": te[1],\n",
        "                \"epochs_used\": len(hist.history[\"loss\"])\n",
        "            })\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DzrVe3Kg2fI",
        "outputId": "6c0e6224-c251-46b1-bf69-8c3e8e07b965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Full Results (sorted by Test R²) ===\n",
            "optimizer     lr  train_r2  val_r2  test_r2  val_mse  test_mse  val_mae  test_mae  epochs_used\n",
            "     adam 0.0200    0.8921  0.5980   0.8980   0.0118    0.0032   0.0752    0.0485          183\n",
            "     adam 0.0100    0.8930  0.5958   0.8929   0.0119    0.0034   0.0752    0.0500          304\n",
            "     adam 0.0070    0.8933  0.5976   0.8897   0.0118    0.0035   0.0750    0.0507          414\n",
            "     adam 0.0050    0.8938  0.5989   0.8864   0.0118    0.0036   0.0750    0.0513          566\n",
            "\n",
            "=== Best Configs ===\n",
            "Best R² :  {'optimizer': 'adam', 'lr': 0.02, 'train_r2': 0.892145724458597, 'val_r2': 0.5980032201365011, 'test_r2': 0.8980325155068367, 'val_mse': 0.011786760402627024, 'test_mse': 0.003195705176479718, 'val_mae': 0.0751653652071953, 'test_mae': 0.04845859555602068, 'epochs_used': 183}\n",
            "Best MSE:  {'optimizer': 'adam', 'lr': 0.02, 'train_r2': 0.892145724458597, 'val_r2': 0.5980032201365011, 'test_r2': 0.8980325155068367, 'val_mse': 0.011786760402627024, 'test_mse': 0.003195705176479718, 'val_mae': 0.0751653652071953, 'test_mae': 0.04845859555602068, 'epochs_used': 183}\n",
            "Best MAE:  {'optimizer': 'adam', 'lr': 0.02, 'train_r2': 0.892145724458597, 'val_r2': 0.5980032201365011, 'test_r2': 0.8980325155068367, 'val_mse': 0.011786760402627024, 'test_mse': 0.003195705176479718, 'val_mae': 0.0751653652071953, 'test_mae': 0.04845859555602068, 'epochs_used': 183}\n"
          ]
        }
      ],
      "source": [
        "# Run sweep\n",
        "opt_results = sweep_optims(layers=[10,5], acts=\"sigmoid\")\n",
        "\n",
        "# Sort by R² (descending)\n",
        "sorted_r2 = opt_results.sort_values(\"test_r2\", ascending=False)\n",
        "\n",
        "print(\"\\n=== Full Results (sorted by Test R²) ===\")\n",
        "print(sorted_r2.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "# Best configs per metric\n",
        "best_r2  = opt_results.loc[opt_results[\"test_r2\"].idxmax()]\n",
        "best_mse = opt_results.loc[opt_results[\"test_mse\"].idxmin()]\n",
        "best_mae = opt_results.loc[opt_results[\"test_mae\"].idxmin()]\n",
        "\n",
        "print(\"\\n=== Best Configs ===\")\n",
        "print(\"Best R² : \", best_r2.to_dict())\n",
        "print(\"Best MSE: \", best_mse.to_dict())\n",
        "print(\"Best MAE: \", best_mae.to_dict())\n",
        "\n",
        "# (Optional) Save to CSV for analysis later\n",
        "opt_results.to_csv(\"optimizer_lr_results.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM8API4RhcG/fcqeM6K5NLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}